---
layout: post
title: "NCTU-3DFixation Dataset"
date: 2015-05-01
desc: "NCTU-3DFixation Dataset"
keywords: "dataset"
categories: [Project]
tags:
icon:
---

<meta name="citation_title" content="NCTU-3DFixation Dataset">
<meta name="citation_author" content="Ma, Chih-Yao">
<meta name="citation_author" content="Hang, Hsueh-Ming">
<meta name="citation_publication_date" content="2015/05/01">
<meta name="citation_pdf_url" content="https://jov.arvojournals.org/article.aspx?articleid=2300610">

<head>
<style>
.gunimage {
  display: inline-block;
  margin-left: auto;
  margin-right: auto;
  width: 15%;
}
.half {
  width:50%;
  float: left;
}
.third {
  width:33%;
  float: left;
}
#images {
  text-align: center;
  width: 100%;
}
div.section_header {
  font-size: x-large;
  color: rgb(30,144,255);
}
</style>
</head>

## **NCTU-3DFixation Dataset**

[**Chih-Yao Ma**](https://chihyaoma.github.io/), [Hsueh-Ming Hang](https://www.hmhang.com/)<br>
Journal of Vision, 2015 <br>

[[Paper]](http://jov.arvojournals.org/article.aspx?articleid=2300610)

---

<div class="section_header">Abstract</div>
The eye fixation data is essential for studying the way humans understand the image contents. Up to now, the public-domain 3D fixation data are scarce. Therefore, we conduct our eye fixation experiments on 3D images. The resultant dataset should be useful to the 3D visual attention research community. Our eye fixation dataset comprises 475 3D images and 16 subjects. We use a Tobii TX300 eye-tracker to track the eye movement of each subject. In addition, this database contains 475 computed depth maps. The database and the MATLAB source codes for evaluation and visualization are released on this webpage.

---

<div class="section_header">Proposed Concept</div>

<!-- <p align="center">
<img src="../../../../static/assets/img/blog/fixation.png?raw=true" width="50%">
</p> -->

<div class="row">
  <div class="third">
    <p align="center">
        <img src="../../../../static/assets/img/blog/rgb-depth-fixation.png?raw=true" alt="Snow" style="width:75%">
    </p>
  </div>
  <div class="third">
    <p align="center">
        <img src="../../../../static/assets/img/blog/fixation.png?raw=true" alt="Forest" style="width:100%">
    </p>
  </div>
  <div class="third">
    <p align="center">
        <img src="../../../../static/assets/img/blog/tobii.png?raw=true" alt="Forest" style="width:100%">
    </p>
  </div>
  
</div>

---

<div class="section_header">Download</div>

All image contents provided in the NCTU-3DFixation Database are solely intended for private and research purposes only and copyrighted by their respective owners unless otherwise stated.

I have compressed all the files together to create one zip file which is currently **PASSWARD** protected.

[NCTU-3DFixation.zip](http://cwww.ee.nctu.edu.tw/wiki/core/uploads/People/HangResearchMaterial/NCTU-3DFixation.zip) (4.7GB)

<div class="text-gray mb-2">
    Password: c-o-m-m-l-a-b- (without "-")
</div>

<br>
If the above link doesn't work or somehow gives you low download speed, please refer to this [Google Drive link](https://drive.google.com/open?id=1lgPDBOEYj7TgD3pjINn-d5OOImrafeEb) for downloading our dataset.

This compressed file includes:

- 475 3D images
- Generated Depth maps
- Gaze data from 16 subjects
- MATLAB Codes for visualization and evaluation

If you have any questions regards to our database, please don't hesitate to contact me.

---

<div class="section_header">Citation</div>
If you find this work useful, please cite our paper:
<pre><code>
@article{ma2015learning,
    title={Learning-based saliency model with depth information},
    author={Ma, Chih-Yao and Hang, Hsueh-Ming},
    journal={Journal of vision},
    volume={15},
    number={6},
    pages={19--19},
    year={2015},
    publisher={The Association for Research in Vision and Ophthalmology}
}
</code></pre>
